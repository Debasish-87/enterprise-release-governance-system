name: Intelligent Testing Pipeline

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:

permissions:
  contents: write

jobs:

  # ============================================================
  #  LAYER 1 — Application Testing + Allure Report
  # ============================================================
  application-testing:
    name: Layer 1 - Application Testing + Allure
    runs-on: ubuntu-latest
    timeout-minutes: 25

    steps:
      - name: Checkout Testing Platform Repo
        uses: actions/checkout@v4

      - name: Stage 1 - Validate Repository Structure
        run: |
          echo "===== Repo Root Files ====="
          ls -la

          echo "===== Checking required folders ====="
          test -d application-testing || (echo "❌ application-testing folder missing" && exit 1)
          test -d security-testing || (echo "❌ security-testing folder missing" && exit 1)
          test -d sbom-testing || (echo "❌ sbom-testing folder missing" && exit 1)
          test -d kpqe-platform-testing || (echo "❌ kpqe-platform-testing folder missing" && exit 1)
          test -d release-dashboard || (echo "❌ release-dashboard folder missing" && exit 1)

          echo "===== Checking required files ====="
          test -f application-testing/pom.xml || (echo "❌ application-testing/pom.xml missing" && exit 1)
          test -f security-testing/run-gitleaks.sh || (echo "❌ run-gitleaks.sh missing" && exit 1)
          test -f security-testing/run-semgrep.sh || (echo "❌ run-semgrep.sh missing" && exit 1)
          test -f security-testing/run-trivy.sh || (echo "❌ run-trivy.sh missing" && exit 1)

          echo "✅ Stage 1 validation passed"

      - name: Setup Java 21
        uses: actions/setup-java@v4
        with:
          distribution: "temurin"
          java-version: "21"
          cache: "maven"

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Chrome dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libnss3 \
            libxss1 \
            libasound2t64 \
            libatk-bridge2.0-0 \
            libgtk-3-0 \
            libgbm1 \
            fonts-liberation \
            xdg-utils \
            unzip \
            curl

      - name: Setup Chrome
        uses: browser-actions/setup-chrome@v1

      - name: Debug Chrome + System Versions
        run: |
          echo "===== Chrome Version ====="
          google-chrome --version || true

          echo "===== Chromedriver Version ====="
          chromedriver --version || true

          echo "===== Java Version ====="
          java -version || true

          echo "===== Maven Version ====="
          mvn -v || true

          echo "===== Python Version ====="
          python --version || true

      - name: Clone Target Big Mart Repo
        run: |
          git clone https://github.com/asutosh-2000/Big-Mart-Sales-Prediction.git target-app
          echo "===== Target Repo Files ====="
          ls -la target-app

      - name: Install Flask App Dependencies
        run: |
          cd target-app
          python -m pip install --upgrade pip
          pip install flask joblib pandas numpy scikit-learn xgboost

      - name: Start Flask App
        run: |
          cd target-app

          export FLASK_ENV=production
          export PYTHONUNBUFFERED=1

          nohup python app.py > flask.log 2>&1 &
          echo $! > flask.pid

          echo "Flask PID: $(cat flask.pid)"
          sleep 6

          echo "===== Flask Log (After Start) ====="
          cat flask.log || true

          echo "===== Running Python Processes ====="
          ps aux | grep python || true

          echo "===== Ports Listening ====="
          ss -ltnp || true

      - name: Verify Flask App
        run: |
          echo "===== Checking Flask Health ====="

          for i in {1..40}; do
            echo "Checking Flask... attempt $i"

            if curl -s -o /dev/null -w "%{http_code}" http://127.0.0.1:9457 | grep -q "200"; then
              echo "✅ Flask is UP on port 9457"
              exit 0
            fi

            sleep 2
          done

          echo "❌ Flask did not start properly"
          cat target-app/flask.log || true
          exit 1

      - name: Run Automation Tests
        run: |
          cd application-testing
          mvn clean test -Dheadless=true

      - name: Generate Allure Report (CLI Mode)
        if: always()
        run: |
          echo "===== Installing Allure CLI ====="
          curl -Ls https://github.com/allure-framework/allure2/releases/download/2.27.0/allure-2.27.0.tgz -o allure.tgz
          tar -xzf allure.tgz
          sudo mv allure-2.27.0 /opt/allure
          sudo ln -sf /opt/allure/bin/allure /usr/local/bin/allure

          echo "===== Generating Allure Report ====="
          cd application-testing
          mkdir -p target/site/allure-report
          allure generate target/allure-results -o target/site/allure-report --clean

      - name: Upload Allure Report as Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: allure-report
          path: application-testing/target/site/allure-report

      - name: Upload Flask Logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: flask-log
          path: target-app/flask.log

      - name: Deploy Allure Report to GitHub Pages
        if: always()
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: application-testing/target/site/allure-report
          publish_branch: gh-pages
          force_orphan: true


  # ============================================================
  #  LAYER 2 — Security Testing
  # ============================================================
  security-testing:
    name: Layer 2 - Security Testing (Gitleaks + Semgrep + Trivy)
    runs-on: ubuntu-latest
    needs: application-testing
    timeout-minutes: 20

    steps:
      - name: Checkout Governance Repo
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Clone Target Big Mart Repo
        run: |
          git clone https://github.com/asutosh-2000/Big-Mart-Sales-Prediction.git target-app
          echo "===== Repo Root ====="
          ls -la
          echo "===== Target Repo ====="
          ls -la target-app

      - name: Make scripts executable
        run: chmod +x security-testing/*.sh

      - name: Run Gitleaks (scan target-app)
        run: ./security-testing/run-gitleaks.sh target-app || true

      - name: Run Semgrep (scan target-app)
        run: ./security-testing/run-semgrep.sh target-app || true

      - name: Run Trivy (scan target-app)
        run: ./security-testing/run-trivy.sh target-app || true

      - name: Upload Security Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-reports
          path: security-testing/reports/


  # ============================================================
  #  LAYER 3 — SBOM
  # ============================================================
  sbom-testing:
    name: Layer 3 - SBOM Generation + SBOM Vulnerability Scan
    runs-on: ubuntu-latest
    needs: security-testing
    timeout-minutes: 20

    steps:
      - name: Checkout Governance Repo
        uses: actions/checkout@v4

      - name: Clone Target Big Mart Repo
        run: |
          git clone https://github.com/asutosh-2000/Big-Mart-Sales-Prediction.git target-app
          echo "===== Repo Root ====="
          ls -la
          echo "===== Target Repo ====="
          ls -la target-app

      - name: Make SBOM scripts executable
        run: chmod +x sbom-testing/*.sh

      - name: Generate SBOM (CycloneDX JSON)
        run: ./sbom-testing/generate-sbom.sh target-app

      - name: Scan SBOM for Vulnerabilities
        run: ./sbom-testing/scan-sbom.sh

      - name: Upload SBOM Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: sbom-reports
          path: sbom-testing/reports/


  # ============================================================
  #  LAYER 4 — KPQE Platform Testing (KIND + pytest)
  # ============================================================
  kpqe-platform-testing:
    name: Layer 4 - Kubernetes Readiness + KPQE Platform Testing
    runs-on: ubuntu-latest
    needs: sbom-testing
    timeout-minutes: 20

    steps:
      - name: Checkout Governance Repo
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -Ls https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/kubectl
          kubectl version --client

      - name: Setup KIND cluster
        uses: helm/kind-action@v1.10.0
        with:
          cluster_name: kpqe-cluster

      # ✅ GUARANTEED FIX: kubeconfig set
      - name: Set kubeconfig explicitly
        run: |
          echo "KUBECONFIG=$HOME/.kube/config" >> $GITHUB_ENV
          kubectl config get-contexts
          kubectl config current-context

      # ✅ GUARANTEED FIX: wait for API ready
      - name: Wait for Kubernetes API Ready
        run: |
          for i in {1..30}; do
            kubectl get nodes && break
            echo "Waiting for cluster..."
            sleep 3
          done

      - name: Verify Kubernetes Cluster
        run: |
          kubectl cluster-info
          kubectl get nodes -o wide
          kubectl get namespaces

      - name: Install KPQE Python requirements
        run: |
          cd kpqe-platform-testing
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Apply KPQE Namespace + RBAC
        run: |
          kubectl apply -f kpqe-platform-testing/k8s/namespace.yaml
          kubectl apply -f kpqe-platform-testing/k8s/kpqe-rbac.yaml

      - name: Run KPQE Platform Tests
        run: |
          cd kpqe-platform-testing
          pytest -q platform-tests --disable-warnings --maxfail=1

      - name: Evaluate KPQE Quality Gate
        if: always()
        run: |
          cd kpqe-platform-testing
          python -m quality_gates.evaluate_platform > kpqe-release-decision.txt
          cat kpqe-release-decision.txt

      - name: Export Cluster + Pod Health (JSON)
        if: always()
        run: |
          mkdir -p kpqe-platform-testing/reports

          echo "Exporting nodes..."
          kubectl get nodes -o json > kpqe-platform-testing/reports/nodes.json

          echo "Exporting pods..."
          kubectl get pods -A -o json > kpqe-platform-testing/reports/pods.json

          echo "Exporting namespaces..."
          kubectl get ns -o json > kpqe-platform-testing/reports/namespaces.json

      - name: Upload KPQE Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: kpqe-platform-reports
          path: |
            kpqe-platform-testing/kpqe-release-decision.txt
            kpqe-platform-testing/reports/


  # ============================================================
  #  LAYER 5 — Release Dashboard
  # ============================================================
  release-dashboard:
    name: Layer 5 - Single Consolidated Release Dashboard
    runs-on: ubuntu-latest
    needs: kpqe-platform-testing
    timeout-minutes: 10

    steps:
      - name: Checkout Governance Repo
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download all workflow artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Debug - list artifacts folder
        run: |
          echo "===== ARTIFACTS ====="
          ls -R artifacts || true

      - name: Prepare dashboard inputs
        run: |
          mkdir -p security-testing/reports
          mkdir -p sbom-testing/reports
          mkdir -p kpqe-platform-testing/reports
          mkdir -p application-testing/target/site/allure-report

          # Allure
          cp -r artifacts/allure-report/* application-testing/target/site/allure-report/ || true

          # Security
          cp -r artifacts/security-reports/* security-testing/reports/ || true

          # SBOM
          cp -r artifacts/sbom-reports/* sbom-testing/reports/ || true

          # KPQE (this artifact contains both txt + reports)
          cp -r artifacts/kpqe-platform-reports/* kpqe-platform-testing/ || true

      - name: Generate dashboard
        run: |
          python release-dashboard/generate-dashboard.py

      - name: Debug - dashboard output
        run: |
          echo "===== DASHBOARD OUTPUT ====="
          ls -la release-dashboard || true
          ls -la release-dashboard/output || true

      - name: Upload Release Dashboard Artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: release-dashboard
          path: |
            release-dashboard/index.html
            release-dashboard/release-summary.json


  # ============================================================
  #  LAYER 6 — Final Release Decision Engine (GO / HOLD / NO-GO)
  # ============================================================
  final-release-decision:
    name: Layer 6 - Final Release Decision Engine
    runs-on: ubuntu-latest
    needs: release-dashboard
    timeout-minutes: 10

    steps:
      - name: Checkout Governance Repo
        uses: actions/checkout@v4

      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install decision engine requirements
        run: |
          python -m pip install --upgrade pip
          pip install -r release-decision/requirements.txt

      - name: Download Release Dashboard Artifact
        uses: actions/download-artifact@v4
        with:
          name: release-dashboard
          path: release-dashboard-artifact

      - name: Debug - check dashboard artifact files
        run: |
          echo "===== release-dashboard-artifact ====="
          ls -la release-dashboard-artifact || true

      - name: Copy release-summary.json into decision engine input folder
        run: |
          mkdir -p release-decision/input

          if [ ! -f "release-dashboard-artifact/release-summary.json" ]; then
            echo "❌ release-summary.json missing from dashboard artifact"
            exit 1
          fi

          cp release-dashboard-artifact/release-summary.json release-decision/input/release-summary.json
          echo "✅ Copied release-summary.json successfully"
          ls -la release-decision/input

      - name: Run Final Release Decision Engine
        run: |
          python release-decision/final-decision.py

      - name: Upload Final Decision Artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: final-release-decision
          path: release-decision/output/
